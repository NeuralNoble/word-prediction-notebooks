{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU0UGwAQl21U",
        "outputId": "d820d689-c797-4544-85ff-99833911cea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n",
            "\n",
            "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.\n",
            "\n",
            "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several ye\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "txt_files = [file for file in os.listdir() if file.endswith('.txt')]\n",
        "\n",
        "txt_files.sort()\n",
        "\n",
        "combined_text = \"\"\n",
        "\n",
        "for book in txt_files:\n",
        "  with open(book,'r',encoding='utf-8') as file:\n",
        "    combined_text += file.read() + \"\\n\\n\"\n",
        "\n",
        "print(combined_text[:1000])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import re"
      ],
      "metadata": {
        "id": "Zp1TXo1gmAEP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "SUdwIrhBmBo7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([combined_text])"
      ],
      "metadata": {
        "id": "WVhSUUGUmDu_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Ai3SQgmFSx",
        "outputId": "3fb948ed-a137-49d6-e3de-6f197ee3da9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10441"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in combined_text.split('.'):  # Assuming sentences are split by periods\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "C3sw1DmomGrX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len =  max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "u0KcIxCzmIey"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdLRLJhqmKF_",
        "outputId": "f8f818ee-61c6-4d9b-9b8e-a10972be3cc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "213"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9ci5DqEdmLI0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "JDYvNJtpmNKh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "nCkHYkrdmOLm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "y_sparse = csr_matrix((np.ones(len(y)), (np.arange(len(y)), y)), shape=(len(y), total_words))"
      ],
      "metadata": {
        "id": "jcRJpl8bmPV-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(X, y_sparse, batch_size, total_words):\n",
        "    while True:\n",
        "        for start in range(0, len(X), batch_size):\n",
        "            end = min(start + batch_size, len(X))\n",
        "            y_batch = y_sparse[start:end].toarray()\n",
        "            yield X[start:end], y_batch\n",
        "\n",
        "batch_size = 128\n",
        "steps_per_epoch = len(X) // batch_size\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_len-1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(data_generator(X, y_sparse, batch_size, total_words), epochs=100, steps_per_epoch=steps_per_epoch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEFMmgU_mQrQ",
        "outputId": "1e2e340a-3b94-4a02-9ab1-3e9dcf81c70a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1243/1243 [==============================] - 61s 44ms/step - loss: 6.6494 - accuracy: 0.0669\n",
            "Epoch 2/100\n",
            "1243/1243 [==============================] - 44s 35ms/step - loss: 5.8219 - accuracy: 0.1189\n",
            "Epoch 3/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 5.3856 - accuracy: 0.1409\n",
            "Epoch 4/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 5.0884 - accuracy: 0.1563\n",
            "Epoch 5/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 4.8429 - accuracy: 0.1678\n",
            "Epoch 6/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 4.6665 - accuracy: 0.1778\n",
            "Epoch 7/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 4.4889 - accuracy: 0.1886\n",
            "Epoch 8/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 4.3061 - accuracy: 0.2016\n",
            "Epoch 9/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 4.1316 - accuracy: 0.2160\n",
            "Epoch 10/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 4.0334 - accuracy: 0.2259\n",
            "Epoch 11/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.9038 - accuracy: 0.2405\n",
            "Epoch 12/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 3.7930 - accuracy: 0.2547\n",
            "Epoch 13/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 3.6571 - accuracy: 0.2713\n",
            "Epoch 14/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.5809 - accuracy: 0.2807\n",
            "Epoch 15/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.4433 - accuracy: 0.2992\n",
            "Epoch 16/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.3215 - accuracy: 0.3159\n",
            "Epoch 17/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.2371 - accuracy: 0.3279\n",
            "Epoch 18/100\n",
            "1243/1243 [==============================] - 44s 35ms/step - loss: 3.1935 - accuracy: 0.3341\n",
            "Epoch 19/100\n",
            "1243/1243 [==============================] - 44s 35ms/step - loss: 3.0913 - accuracy: 0.3504\n",
            "Epoch 20/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 3.0031 - accuracy: 0.3636\n",
            "Epoch 21/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.9746 - accuracy: 0.3665\n",
            "Epoch 22/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.9209 - accuracy: 0.3738\n",
            "Epoch 23/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.8618 - accuracy: 0.3857\n",
            "Epoch 24/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.8189 - accuracy: 0.3903\n",
            "Epoch 25/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.7968 - accuracy: 0.3925\n",
            "Epoch 26/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.7338 - accuracy: 0.4037\n",
            "Epoch 27/100\n",
            "1243/1243 [==============================] - 44s 35ms/step - loss: 2.6093 - accuracy: 0.4246\n",
            "Epoch 28/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.5534 - accuracy: 0.4339\n",
            "Epoch 29/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.4669 - accuracy: 0.4481\n",
            "Epoch 30/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.4163 - accuracy: 0.4555\n",
            "Epoch 31/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.4208 - accuracy: 0.4548\n",
            "Epoch 32/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.3506 - accuracy: 0.4672\n",
            "Epoch 33/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.2736 - accuracy: 0.4808\n",
            "Epoch 34/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.2395 - accuracy: 0.4877\n",
            "Epoch 35/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 2.1985 - accuracy: 0.4936\n",
            "Epoch 36/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 2.1707 - accuracy: 0.4986\n",
            "Epoch 37/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 2.1069 - accuracy: 0.5094\n",
            "Epoch 38/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 2.0693 - accuracy: 0.5173\n",
            "Epoch 39/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 2.0440 - accuracy: 0.5219\n",
            "Epoch 40/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.9995 - accuracy: 0.5297\n",
            "Epoch 41/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.9647 - accuracy: 0.5364\n",
            "Epoch 42/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.9492 - accuracy: 0.5375\n",
            "Epoch 43/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.9861 - accuracy: 0.5307\n",
            "Epoch 44/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.8901 - accuracy: 0.5498\n",
            "Epoch 45/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.8858 - accuracy: 0.5499\n",
            "Epoch 46/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.8526 - accuracy: 0.5567\n",
            "Epoch 47/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.8073 - accuracy: 0.5648\n",
            "Epoch 48/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7904 - accuracy: 0.5673\n",
            "Epoch 49/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7842 - accuracy: 0.5674\n",
            "Epoch 50/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7779 - accuracy: 0.5687\n",
            "Epoch 51/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7544 - accuracy: 0.5735\n",
            "Epoch 52/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7962 - accuracy: 0.5636\n",
            "Epoch 53/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7886 - accuracy: 0.5647\n",
            "Epoch 54/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.7553 - accuracy: 0.5719\n",
            "Epoch 55/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6996 - accuracy: 0.5834\n",
            "Epoch 56/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6711 - accuracy: 0.5898\n",
            "Epoch 57/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6829 - accuracy: 0.5859\n",
            "Epoch 58/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6496 - accuracy: 0.5933\n",
            "Epoch 59/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6220 - accuracy: 0.5984\n",
            "Epoch 60/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6178 - accuracy: 0.5999\n",
            "Epoch 61/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6301 - accuracy: 0.5963\n",
            "Epoch 62/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.6152 - accuracy: 0.6011\n",
            "Epoch 63/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5943 - accuracy: 0.6038\n",
            "Epoch 64/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5811 - accuracy: 0.6056\n",
            "Epoch 65/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5497 - accuracy: 0.6127\n",
            "Epoch 66/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5311 - accuracy: 0.6171\n",
            "Epoch 67/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5367 - accuracy: 0.6145\n",
            "Epoch 68/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5862 - accuracy: 0.6047\n",
            "Epoch 69/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5286 - accuracy: 0.6166\n",
            "Epoch 70/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5137 - accuracy: 0.6184\n",
            "Epoch 71/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5032 - accuracy: 0.6214\n",
            "Epoch 72/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4934 - accuracy: 0.6219\n",
            "Epoch 73/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4871 - accuracy: 0.6243\n",
            "Epoch 74/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4738 - accuracy: 0.6262\n",
            "Epoch 75/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4493 - accuracy: 0.6330\n",
            "Epoch 76/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4695 - accuracy: 0.6287\n",
            "Epoch 77/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4435 - accuracy: 0.6338\n",
            "Epoch 78/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4716 - accuracy: 0.6276\n",
            "Epoch 79/100\n",
            "1243/1243 [==============================] - 45s 37ms/step - loss: 1.4444 - accuracy: 0.6328\n",
            "Epoch 80/100\n",
            "1243/1243 [==============================] - 45s 37ms/step - loss: 1.4227 - accuracy: 0.6388\n",
            "Epoch 81/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4412 - accuracy: 0.6331\n",
            "Epoch 82/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4339 - accuracy: 0.6348\n",
            "Epoch 83/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4058 - accuracy: 0.6412\n",
            "Epoch 84/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.5491 - accuracy: 0.6118\n",
            "Epoch 85/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4234 - accuracy: 0.6378\n",
            "Epoch 86/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3894 - accuracy: 0.6457\n",
            "Epoch 87/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3736 - accuracy: 0.6476\n",
            "Epoch 88/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4218 - accuracy: 0.6367\n",
            "Epoch 89/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4519 - accuracy: 0.6308\n",
            "Epoch 90/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3939 - accuracy: 0.6422\n",
            "Epoch 91/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3864 - accuracy: 0.6443\n",
            "Epoch 92/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3996 - accuracy: 0.6414\n",
            "Epoch 93/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3653 - accuracy: 0.6484\n",
            "Epoch 94/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.4053 - accuracy: 0.6395\n",
            "Epoch 95/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3939 - accuracy: 0.6423\n",
            "Epoch 96/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3450 - accuracy: 0.6520\n",
            "Epoch 97/100\n",
            "1243/1243 [==============================] - 45s 36ms/step - loss: 1.3194 - accuracy: 0.6593\n",
            "Epoch 98/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 1.4049 - accuracy: 0.6403\n",
            "Epoch 99/100\n",
            "1243/1243 [==============================] - 44s 36ms/step - loss: 1.3874 - accuracy: 0.6442\n",
            "Epoch 100/100\n",
            "1243/1243 [==============================] - 44s 35ms/step - loss: 1.3358 - accuracy: 0.6548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_text(seed_text, model, tokenizer, max_sequence_len, num_words_to_generate):\n",
        "    for _ in range(num_words_to_generate):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "\n",
        "seed_text = \"who is dumbledore? \"\n",
        "num_words_to_generate = 50\n",
        "generated_text = generate_text(seed_text, model, tokenizer, max_len, num_words_to_generate)\n",
        "\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eNhzmwAmSq3",
        "outputId": "9cb46c49-f2c5-4082-fff5-43084efa3faf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "who is dumbledore?  the most wizard of hogwarts and the sorting hat is match in the world ” said harry loudly to the dark one of the house and the note was still around the castle with the second harry had never seen before it was downstairs to the fire which was a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQH2BVIK3iiq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}